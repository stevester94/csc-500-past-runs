[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 1204], examples_per_second: 2523.8740, train_label_loss: 2.7721, train_domain_loss: 0.5197
epoch: 1, [batch: 241 / 1204], examples_per_second: 12133.2712, train_label_loss: 2.3945, train_domain_loss: 0.3208
epoch: 1, [batch: 482 / 1204], examples_per_second: 12336.3811, train_label_loss: 2.4067, train_domain_loss: 0.3218
epoch: 1, [batch: 722 / 1204], examples_per_second: 12307.9190, train_label_loss: 2.4133, train_domain_loss: 0.3275
epoch: 1, [batch: 963 / 1204], examples_per_second: 12310.3628, train_label_loss: 2.3992, train_domain_loss: 0.3342
=============================================================
epoch: 1, source_val_acc_label: 0.0871, target_val_acc_label: 0.0915, source_val_label_loss: 2.4012, target_val_label_loss: 2.4005, source_and_target_val_domain_loss: 0.6955
=============================================================
New best
epoch: 2, [batch: 1 / 1204], examples_per_second: 77.8249, train_label_loss: 2.4103, train_domain_loss: 0.3423
epoch: 2, [batch: 241 / 1204], examples_per_second: 12303.9312, train_label_loss: 2.3949, train_domain_loss: 0.3587
epoch: 2, [batch: 482 / 1204], examples_per_second: 12306.6733, train_label_loss: 2.3994, train_domain_loss: 0.4515
epoch: 2, [batch: 722 / 1204], examples_per_second: 12324.4252, train_label_loss: 2.3856, train_domain_loss: 0.5258
epoch: 2, [batch: 963 / 1204], examples_per_second: 12377.7530, train_label_loss: 2.3977, train_domain_loss: 0.5301
=============================================================
epoch: 2, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3998, target_val_label_loss: 2.3993, source_and_target_val_domain_loss: 1.0175
=============================================================
New best
epoch: 3, [batch: 1 / 1204], examples_per_second: 83.3804, train_label_loss: 2.3987, train_domain_loss: 0.5301
epoch: 3, [batch: 241 / 1204], examples_per_second: 12120.3183, train_label_loss: 2.4124, train_domain_loss: 0.5301
epoch: 3, [batch: 482 / 1204], examples_per_second: 12239.7587, train_label_loss: 2.3988, train_domain_loss: 0.5301
epoch: 3, [batch: 722 / 1204], examples_per_second: 12312.8906, train_label_loss: 2.4094, train_domain_loss: 0.5251
epoch: 3, [batch: 963 / 1204], examples_per_second: 12302.5180, train_label_loss: 2.4099, train_domain_loss: 0.5294
=============================================================
epoch: 3, source_val_acc_label: 0.0903, target_val_acc_label: 0.0905, source_val_label_loss: 2.3987, target_val_label_loss: 2.3989, source_and_target_val_domain_loss: 1.0169
=============================================================
New best
epoch: 4, [batch: 1 / 1204], examples_per_second: 82.4807, train_label_loss: 2.4009, train_domain_loss: 0.5301
epoch: 4, [batch: 241 / 1204], examples_per_second: 12276.4421, train_label_loss: 2.3942, train_domain_loss: 0.5301
epoch: 4, [batch: 482 / 1204], examples_per_second: 12260.1700, train_label_loss: 2.3971, train_domain_loss: 0.5301
epoch: 4, [batch: 722 / 1204], examples_per_second: 12308.9607, train_label_loss: 2.4016, train_domain_loss: 0.5301
epoch: 4, [batch: 963 / 1204], examples_per_second: 12082.9979, train_label_loss: 2.3998, train_domain_loss: 0.5301
=============================================================
epoch: 4, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3984, target_val_label_loss: 2.3985, source_and_target_val_domain_loss: 1.0365
=============================================================
New best
epoch: 5, [batch: 1 / 1204], examples_per_second: 83.3059, train_label_loss: 2.3986, train_domain_loss: 0.5301
epoch: 5, [batch: 241 / 1204], examples_per_second: 12278.5397, train_label_loss: 2.3975, train_domain_loss: 0.5301
epoch: 5, [batch: 482 / 1204], examples_per_second: 12331.5358, train_label_loss: 2.3949, train_domain_loss: 0.5301
epoch: 5, [batch: 722 / 1204], examples_per_second: 12354.9120, train_label_loss: 2.3950, train_domain_loss: 0.5301
epoch: 5, [batch: 963 / 1204], examples_per_second: 12294.5372, train_label_loss: 2.4043, train_domain_loss: 0.5301
=============================================================
epoch: 5, source_val_acc_label: 0.0918, target_val_acc_label: 0.0930, source_val_label_loss: 2.3983, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 1.0268
=============================================================
New best
epoch: 6, [batch: 1 / 1204], examples_per_second: 82.7714, train_label_loss: 2.4001, train_domain_loss: 0.5301
epoch: 6, [batch: 241 / 1204], examples_per_second: 12184.2813, train_label_loss: 2.3934, train_domain_loss: 0.5301
epoch: 6, [batch: 482 / 1204], examples_per_second: 12361.3108, train_label_loss: 2.4049, train_domain_loss: 0.5301
epoch: 6, [batch: 722 / 1204], examples_per_second: 12327.0805, train_label_loss: 2.3982, train_domain_loss: 0.5301
epoch: 6, [batch: 963 / 1204], examples_per_second: 12328.6136, train_label_loss: 2.4044, train_domain_loss: 0.5301
=============================================================
epoch: 6, source_val_acc_label: 0.0871, target_val_acc_label: 0.0915, source_val_label_loss: 2.3982, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 1.0104
=============================================================
New best
epoch: 7, [batch: 1 / 1204], examples_per_second: 83.3287, train_label_loss: 2.3976, train_domain_loss: 0.5301
epoch: 7, [batch: 241 / 1204], examples_per_second: 12349.9111, train_label_loss: 2.3995, train_domain_loss: 0.5300
epoch: 7, [batch: 482 / 1204], examples_per_second: 12400.4195, train_label_loss: 2.4037, train_domain_loss: 0.5301
epoch: 7, [batch: 722 / 1204], examples_per_second: 12376.1053, train_label_loss: 2.3931, train_domain_loss: 0.5301
epoch: 7, [batch: 963 / 1204], examples_per_second: 12323.2110, train_label_loss: 2.3991, train_domain_loss: 0.5301
=============================================================
epoch: 7, source_val_acc_label: 0.0903, target_val_acc_label: 0.0900, source_val_label_loss: 2.3982, target_val_label_loss: 2.3984, source_and_target_val_domain_loss: 1.0142
=============================================================
epoch: 8, [batch: 1 / 1204], examples_per_second: 83.5472, train_label_loss: 2.3937, train_domain_loss: 0.5309
epoch: 8, [batch: 241 / 1204], examples_per_second: 12256.2226, train_label_loss: 2.3989, train_domain_loss: 0.5301
epoch: 8, [batch: 482 / 1204], examples_per_second: 12240.0077, train_label_loss: 2.4007, train_domain_loss: 0.5300
epoch: 8, [batch: 722 / 1204], examples_per_second: 12295.3356, train_label_loss: 2.3981, train_domain_loss: 0.5314
epoch: 8, [batch: 963 / 1204], examples_per_second: 12320.7467, train_label_loss: 2.3966, train_domain_loss: 0.5301
=============================================================
epoch: 8, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3981, target_val_label_loss: 2.3983, source_and_target_val_domain_loss: 1.0342
=============================================================
epoch: 9, [batch: 1 / 1204], examples_per_second: 82.6169, train_label_loss: 2.3980, train_domain_loss: 0.5301
epoch: 9, [batch: 241 / 1204], examples_per_second: 12253.0443, train_label_loss: 2.3943, train_domain_loss: 0.5301
epoch: 9, [batch: 482 / 1204], examples_per_second: 12291.6768, train_label_loss: 2.4008, train_domain_loss: 0.5301
epoch: 9, [batch: 722 / 1204], examples_per_second: 12350.4344, train_label_loss: 2.4072, train_domain_loss: 0.5273
epoch: 9, [batch: 963 / 1204], examples_per_second: 12340.4487, train_label_loss: 2.3970, train_domain_loss: 0.5301
=============================================================
epoch: 9, source_val_acc_label: 0.0924, target_val_acc_label: 0.0898, source_val_label_loss: 2.3982, target_val_label_loss: 2.3982, source_and_target_val_domain_loss: 0.7512
=============================================================
epoch: 10, [batch: 1 / 1204], examples_per_second: 83.0675, train_label_loss: 2.4033, train_domain_loss: 0.5301
epoch: 10, [batch: 241 / 1204], examples_per_second: 12264.1880, train_label_loss: 2.3982, train_domain_loss: 0.5301
epoch: 10, [batch: 482 / 1204], examples_per_second: 12317.9667, train_label_loss: 2.3987, train_domain_loss: 0.5301
epoch: 10, [batch: 722 / 1204], examples_per_second: 12336.5166, train_label_loss: 2.4022, train_domain_loss: 0.5301
epoch: 10, [batch: 963 / 1204], examples_per_second: 12324.8861, train_label_loss: 2.3933, train_domain_loss: 0.5301
=============================================================
epoch: 10, source_val_acc_label: 0.0905, target_val_acc_label: 0.0910, source_val_label_loss: 2.3981, target_val_label_loss: 2.3982, source_and_target_val_domain_loss: 1.0270
=============================================================
epoch: 11, [batch: 1 / 1204], examples_per_second: 82.3321, train_label_loss: 2.4002, train_domain_loss: 0.5301
epoch: 11, [batch: 241 / 1204], examples_per_second: 12176.7772, train_label_loss: 2.4008, train_domain_loss: 0.5301
epoch: 11, [batch: 482 / 1204], examples_per_second: 12076.2730, train_label_loss: 2.3950, train_domain_loss: 0.5301
epoch: 11, [batch: 722 / 1204], examples_per_second: 12064.7916, train_label_loss: 2.3974, train_domain_loss: 0.5300
epoch: 11, [batch: 963 / 1204], examples_per_second: 12343.5426, train_label_loss: 2.3940, train_domain_loss: 0.5301
=============================================================
epoch: 11, source_val_acc_label: 0.0932, target_val_acc_label: 0.0942, source_val_label_loss: 2.3980, target_val_label_loss: 2.3981, source_and_target_val_domain_loss: 1.0279
=============================================================
New best
epoch: 12, [batch: 1 / 1204], examples_per_second: 82.7077, train_label_loss: 2.3965, train_domain_loss: 0.5302
epoch: 12, [batch: 241 / 1204], examples_per_second: 12358.7349, train_label_loss: 2.4027, train_domain_loss: 0.5272
epoch: 12, [batch: 482 / 1204], examples_per_second: 12329.4183, train_label_loss: 2.3966, train_domain_loss: 0.5309
epoch: 12, [batch: 722 / 1204], examples_per_second: 12374.9155, train_label_loss: 2.4006, train_domain_loss: 0.5301
epoch: 12, [batch: 963 / 1204], examples_per_second: 12396.5712, train_label_loss: 2.4014, train_domain_loss: 0.5310
=============================================================
epoch: 12, source_val_acc_label: 0.0871, target_val_acc_label: 0.0915, source_val_label_loss: 2.3982, target_val_label_loss: 2.3981, source_and_target_val_domain_loss: 0.9810
=============================================================
epoch: 13, [batch: 1 / 1204], examples_per_second: 82.5724, train_label_loss: 2.4008, train_domain_loss: 0.5301
epoch: 13, [batch: 241 / 1204], examples_per_second: 12269.9025, train_label_loss: 2.3924, train_domain_loss: 0.5301
epoch: 13, [batch: 482 / 1204], examples_per_second: 12323.3072, train_label_loss: 2.4046, train_domain_loss: 0.5301
epoch: 13, [batch: 722 / 1204], examples_per_second: 12334.3047, train_label_loss: 2.4026, train_domain_loss: 0.5301
epoch: 13, [batch: 963 / 1204], examples_per_second: 12300.1801, train_label_loss: 2.3961, train_domain_loss: 0.5301
=============================================================
epoch: 13, source_val_acc_label: 0.0903, target_val_acc_label: 0.0905, source_val_label_loss: 2.3981, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 1.0178
=============================================================
New best
epoch: 14, [batch: 1 / 1204], examples_per_second: 83.7559, train_label_loss: 2.3940, train_domain_loss: 0.5301
epoch: 14, [batch: 241 / 1204], examples_per_second: 12297.4444, train_label_loss: 2.3986, train_domain_loss: 0.5301
epoch: 14, [batch: 482 / 1204], examples_per_second: 12326.9163, train_label_loss: 2.4048, train_domain_loss: 0.5301
epoch: 14, [batch: 722 / 1204], examples_per_second: 12365.4503, train_label_loss: 2.4012, train_domain_loss: 0.5301
epoch: 14, [batch: 963 / 1204], examples_per_second: 12381.4379, train_label_loss: 2.4001, train_domain_loss: 0.5276
=============================================================
epoch: 14, source_val_acc_label: 0.0903, target_val_acc_label: 0.0905, source_val_label_loss: 2.3979, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 1.0543
=============================================================
New best
epoch: 15, [batch: 1 / 1204], examples_per_second: 83.9979, train_label_loss: 2.4002, train_domain_loss: 0.5301
epoch: 15, [batch: 241 / 1204], examples_per_second: 12310.5460, train_label_loss: 2.4026, train_domain_loss: 0.5301
epoch: 15, [batch: 482 / 1204], examples_per_second: 12372.7071, train_label_loss: 2.4014, train_domain_loss: 0.5301
epoch: 15, [batch: 722 / 1204], examples_per_second: 12308.5715, train_label_loss: 2.3981, train_domain_loss: 0.5301
epoch: 15, [batch: 963 / 1204], examples_per_second: 12354.1830, train_label_loss: 2.3977, train_domain_loss: 0.5301
=============================================================
epoch: 15, source_val_acc_label: 0.0933, target_val_acc_label: 0.0920, source_val_label_loss: 2.3979, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 1.0583
=============================================================
New best
epoch: 16, [batch: 1 / 1204], examples_per_second: 83.8206, train_label_loss: 2.3986, train_domain_loss: 0.5303
epoch: 16, [batch: 241 / 1204], examples_per_second: 12272.7506, train_label_loss: 2.3973, train_domain_loss: 0.5301
epoch: 16, [batch: 482 / 1204], examples_per_second: 12350.2019, train_label_loss: 2.3984, train_domain_loss: 0.5301
epoch: 16, [batch: 722 / 1204], examples_per_second: 12325.2752, train_label_loss: 2.3929, train_domain_loss: 0.5301
epoch: 16, [batch: 963 / 1204], examples_per_second: 12217.6637, train_label_loss: 2.3963, train_domain_loss: 0.5301
=============================================================
epoch: 16, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3980, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 1.0257
=============================================================
epoch: 17, [batch: 1 / 1204], examples_per_second: 82.9981, train_label_loss: 2.3971, train_domain_loss: 0.5301
epoch: 17, [batch: 241 / 1204], examples_per_second: 12304.5034, train_label_loss: 2.3977, train_domain_loss: 0.5301
epoch: 17, [batch: 482 / 1204], examples_per_second: 12167.9066, train_label_loss: 2.4017, train_domain_loss: 0.5301
epoch: 17, [batch: 722 / 1204], examples_per_second: 12316.4050, train_label_loss: 2.3962, train_domain_loss: 0.5301
epoch: 17, [batch: 963 / 1204], examples_per_second: 12346.4095, train_label_loss: 2.3995, train_domain_loss: 0.5301
=============================================================
epoch: 17, source_val_acc_label: 0.0905, target_val_acc_label: 0.0910, source_val_label_loss: 2.3980, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 0.9781
=============================================================
epoch: 18, [batch: 1 / 1204], examples_per_second: 83.5789, train_label_loss: 2.3985, train_domain_loss: 0.5301
epoch: 18, [batch: 241 / 1204], examples_per_second: 12371.2536, train_label_loss: 2.3990, train_domain_loss: 0.5301
epoch: 18, [batch: 482 / 1204], examples_per_second: 12369.8209, train_label_loss: 2.3997, train_domain_loss: 0.5301
epoch: 18, [batch: 722 / 1204], examples_per_second: 12266.3270, train_label_loss: 2.3947, train_domain_loss: 0.5276
epoch: 18, [batch: 963 / 1204], examples_per_second: 12336.3682, train_label_loss: 2.4007, train_domain_loss: 0.5301
=============================================================
epoch: 18, source_val_acc_label: 0.0903, target_val_acc_label: 0.0905, source_val_label_loss: 2.3980, target_val_label_loss: 2.3981, source_and_target_val_domain_loss: 0.9851
=============================================================
epoch: 19, [batch: 1 / 1204], examples_per_second: 83.7393, train_label_loss: 2.3985, train_domain_loss: 0.5301
epoch: 19, [batch: 241 / 1204], examples_per_second: 12308.7878, train_label_loss: 2.3982, train_domain_loss: 0.5301
epoch: 19, [batch: 482 / 1204], examples_per_second: 12358.5550, train_label_loss: 2.4007, train_domain_loss: 0.5301
epoch: 19, [batch: 722 / 1204], examples_per_second: 12296.2321, train_label_loss: 2.4020, train_domain_loss: 0.5301
epoch: 19, [batch: 963 / 1204], examples_per_second: 12400.7760, train_label_loss: 2.3950, train_domain_loss: 0.5301
=============================================================
epoch: 19, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3980, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 0.9511
=============================================================
epoch: 20, [batch: 1 / 1204], examples_per_second: 83.5444, train_label_loss: 2.3934, train_domain_loss: 0.5301
epoch: 20, [batch: 241 / 1204], examples_per_second: 12298.2601, train_label_loss: 2.4019, train_domain_loss: 0.5301
epoch: 20, [batch: 482 / 1204], examples_per_second: 12357.2189, train_label_loss: 2.3979, train_domain_loss: 0.5301
epoch: 20, [batch: 722 / 1204], examples_per_second: 12477.4121, train_label_loss: 2.3969, train_domain_loss: 0.5301
epoch: 20, [batch: 963 / 1204], examples_per_second: 12512.2104, train_label_loss: 2.3995, train_domain_loss: 0.5301
=============================================================
epoch: 20, source_val_acc_label: 0.0871, target_val_acc_label: 0.0915, source_val_label_loss: 2.3980, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 1.0117
=============================================================
epoch: 21, [batch: 1 / 1204], examples_per_second: 83.0675, train_label_loss: 2.3983, train_domain_loss: 0.5301
epoch: 21, [batch: 241 / 1204], examples_per_second: 12327.6077, train_label_loss: 2.3968, train_domain_loss: 0.5301
epoch: 21, [batch: 482 / 1204], examples_per_second: 12346.6098, train_label_loss: 2.3987, train_domain_loss: 0.5301
epoch: 21, [batch: 722 / 1204], examples_per_second: 12413.9286, train_label_loss: 2.3970, train_domain_loss: 0.5301
epoch: 21, [batch: 963 / 1204], examples_per_second: 12331.5887, train_label_loss: 2.3974, train_domain_loss: 0.5301
=============================================================
epoch: 21, source_val_acc_label: 0.0905, target_val_acc_label: 0.0910, source_val_label_loss: 2.3984, target_val_label_loss: 2.3984, source_and_target_val_domain_loss: 0.8671
=============================================================
epoch: 22, [batch: 1 / 1204], examples_per_second: 82.2143, train_label_loss: 2.3967, train_domain_loss: 0.5301
epoch: 22, [batch: 241 / 1204], examples_per_second: 12278.3010, train_label_loss: 2.3982, train_domain_loss: 0.5301
epoch: 22, [batch: 482 / 1204], examples_per_second: 12305.5555, train_label_loss: 2.3973, train_domain_loss: 0.5301
epoch: 22, [batch: 722 / 1204], examples_per_second: 12382.3339, train_label_loss: 2.3986, train_domain_loss: 0.5301
epoch: 22, [batch: 963 / 1204], examples_per_second: 12340.7629, train_label_loss: 2.3973, train_domain_loss: 0.5301
=============================================================
epoch: 22, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3980, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 1.0001
=============================================================
epoch: 23, [batch: 1 / 1204], examples_per_second: 82.9540, train_label_loss: 2.3996, train_domain_loss: 0.5301
epoch: 23, [batch: 241 / 1204], examples_per_second: 12296.0701, train_label_loss: 2.3989, train_domain_loss: 0.5301
epoch: 23, [batch: 482 / 1204], examples_per_second: 12341.7659, train_label_loss: 2.3988, train_domain_loss: 0.5301
epoch: 23, [batch: 722 / 1204], examples_per_second: 12345.9978, train_label_loss: 2.3968, train_domain_loss: 0.5301
epoch: 23, [batch: 963 / 1204], examples_per_second: 12313.3749, train_label_loss: 2.4015, train_domain_loss: 0.5301
=============================================================
epoch: 23, source_val_acc_label: 0.0924, target_val_acc_label: 0.0898, source_val_label_loss: 2.3980, target_val_label_loss: 2.3981, source_and_target_val_domain_loss: 0.9846
=============================================================
epoch: 24, [batch: 1 / 1204], examples_per_second: 83.2917, train_label_loss: 2.3960, train_domain_loss: 0.5301
epoch: 24, [batch: 241 / 1204], examples_per_second: 12287.9496, train_label_loss: 2.3974, train_domain_loss: 0.5301
epoch: 24, [batch: 482 / 1204], examples_per_second: 12335.7448, train_label_loss: 2.3999, train_domain_loss: 0.5300
epoch: 24, [batch: 722 / 1204], examples_per_second: 12106.8583, train_label_loss: 2.3959, train_domain_loss: 0.5301
epoch: 24, [batch: 963 / 1204], examples_per_second: 12309.2139, train_label_loss: 2.4001, train_domain_loss: 0.5301
=============================================================
epoch: 24, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3980, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 1.0444
=============================================================
epoch: 25, [batch: 1 / 1204], examples_per_second: 83.3173, train_label_loss: 2.3994, train_domain_loss: 0.5301
epoch: 25, [batch: 241 / 1204], examples_per_second: 12317.7508, train_label_loss: 2.3994, train_domain_loss: 0.5301
epoch: 25, [batch: 482 / 1204], examples_per_second: 12393.5326, train_label_loss: 2.3979, train_domain_loss: 0.5301
epoch: 25, [batch: 722 / 1204], examples_per_second: 12354.6703, train_label_loss: 2.3943, train_domain_loss: 0.5300
epoch: 25, [batch: 963 / 1204], examples_per_second: 12346.7677, train_label_loss: 2.3979, train_domain_loss: 0.5301
=============================================================
epoch: 25, source_val_acc_label: 0.0903, target_val_acc_label: 0.0900, source_val_label_loss: 2.3979, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 1.0313
=============================================================
New best
epoch: 26, [batch: 1 / 1204], examples_per_second: 83.0054, train_label_loss: 2.3988, train_domain_loss: 0.5301
epoch: 26, [batch: 241 / 1204], examples_per_second: 12323.5188, train_label_loss: 2.3988, train_domain_loss: 0.5285
epoch: 26, [batch: 482 / 1204], examples_per_second: 12363.6531, train_label_loss: 2.3997, train_domain_loss: 0.5301
epoch: 26, [batch: 722 / 1204], examples_per_second: 12311.1459, train_label_loss: 2.3995, train_domain_loss: 0.5301
epoch: 26, [batch: 963 / 1204], examples_per_second: 12273.5527, train_label_loss: 2.3952, train_domain_loss: 0.5301
=============================================================
epoch: 26, source_val_acc_label: 0.0903, target_val_acc_label: 0.0900, source_val_label_loss: 2.3979, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 0.9595
=============================================================
epoch: 27, [batch: 1 / 1204], examples_per_second: 81.6859, train_label_loss: 2.3986, train_domain_loss: 0.5301
epoch: 27, [batch: 241 / 1204], examples_per_second: 11684.9753, train_label_loss: 2.3998, train_domain_loss: 0.5301
epoch: 27, [batch: 482 / 1204], examples_per_second: 12319.5982, train_label_loss: 2.4001, train_domain_loss: 0.5301
epoch: 27, [batch: 722 / 1204], examples_per_second: 12391.9418, train_label_loss: 2.3979, train_domain_loss: 0.5301
epoch: 27, [batch: 963 / 1204], examples_per_second: 12231.0335, train_label_loss: 2.3968, train_domain_loss: 0.5301
=============================================================
epoch: 27, source_val_acc_label: 0.0905, target_val_acc_label: 0.0910, source_val_label_loss: 2.3979, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 0.9883
=============================================================
epoch: 28, [batch: 1 / 1204], examples_per_second: 81.3187, train_label_loss: 2.3992, train_domain_loss: 0.5301
epoch: 28, [batch: 241 / 1204], examples_per_second: 12246.4829, train_label_loss: 2.3991, train_domain_loss: 0.5301
epoch: 28, [batch: 482 / 1204], examples_per_second: 12370.9800, train_label_loss: 2.3995, train_domain_loss: 0.5301
epoch: 28, [batch: 722 / 1204], examples_per_second: 12397.2606, train_label_loss: 2.3994, train_domain_loss: 0.5301
epoch: 28, [batch: 963 / 1204], examples_per_second: 12316.8949, train_label_loss: 2.4004, train_domain_loss: 0.5301
=============================================================
epoch: 28, source_val_acc_label: 0.0903, target_val_acc_label: 0.0905, source_val_label_loss: 2.3978, target_val_label_loss: 2.3978, source_and_target_val_domain_loss: 1.0431
=============================================================
New best
epoch: 29, [batch: 1 / 1204], examples_per_second: 83.2213, train_label_loss: 2.3980, train_domain_loss: 0.5301
epoch: 29, [batch: 241 / 1204], examples_per_second: 12292.4383, train_label_loss: 2.3953, train_domain_loss: 0.5301
epoch: 29, [batch: 482 / 1204], examples_per_second: 12360.5291, train_label_loss: 2.4019, train_domain_loss: 0.5301
epoch: 29, [batch: 722 / 1204], examples_per_second: 12307.7544, train_label_loss: 2.3970, train_domain_loss: 0.5291
epoch: 29, [batch: 963 / 1204], examples_per_second: 12361.3994, train_label_loss: 2.3959, train_domain_loss: 0.5301
=============================================================
epoch: 29, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3980, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 0.9958
=============================================================
epoch: 30, [batch: 1 / 1204], examples_per_second: 82.9162, train_label_loss: 2.3838, train_domain_loss: 0.5301
epoch: 30, [batch: 241 / 1204], examples_per_second: 12300.5953, train_label_loss: 2.3973, train_domain_loss: 0.5301
epoch: 30, [batch: 482 / 1204], examples_per_second: 12307.4424, train_label_loss: 2.3948, train_domain_loss: 0.5301
epoch: 30, [batch: 722 / 1204], examples_per_second: 12416.2601, train_label_loss: 2.3983, train_domain_loss: 0.5300
epoch: 30, [batch: 963 / 1204], examples_per_second: 12362.5356, train_label_loss: 2.3964, train_domain_loss: 0.5301
=============================================================
epoch: 30, source_val_acc_label: 0.0903, target_val_acc_label: 0.0900, source_val_label_loss: 2.3981, target_val_label_loss: 2.3981, source_and_target_val_domain_loss: 1.0019
=============================================================
epoch: 31, [batch: 1 / 1204], examples_per_second: 83.6297, train_label_loss: 2.3974, train_domain_loss: 0.5301
epoch: 31, [batch: 241 / 1204], examples_per_second: 12319.5103, train_label_loss: 2.3981, train_domain_loss: 0.5301
epoch: 31, [batch: 482 / 1204], examples_per_second: 12370.1331, train_label_loss: 2.3990, train_domain_loss: 0.5301
epoch: 31, [batch: 722 / 1204], examples_per_second: 12313.6177, train_label_loss: 2.3990, train_domain_loss: 0.5301
epoch: 31, [batch: 963 / 1204], examples_per_second: 12364.3904, train_label_loss: 2.3963, train_domain_loss: 0.5301
=============================================================
epoch: 31, source_val_acc_label: 0.0905, target_val_acc_label: 0.0910, source_val_label_loss: 2.3979, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 1.0406
=============================================================
epoch: 32, [batch: 1 / 1204], examples_per_second: 82.8714, train_label_loss: 2.3963, train_domain_loss: 0.5301
epoch: 32, [batch: 241 / 1204], examples_per_second: 12254.8832, train_label_loss: 2.3998, train_domain_loss: 0.5301
epoch: 32, [batch: 482 / 1204], examples_per_second: 12231.0069, train_label_loss: 2.4024, train_domain_loss: 0.5301
epoch: 32, [batch: 722 / 1204], examples_per_second: 12072.7408, train_label_loss: 2.3961, train_domain_loss: 0.5301
epoch: 32, [batch: 963 / 1204], examples_per_second: 12323.0255, train_label_loss: 2.3987, train_domain_loss: 0.5301
=============================================================
epoch: 32, source_val_acc_label: 0.0903, target_val_acc_label: 0.0900, source_val_label_loss: 2.3980, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 1.0356
=============================================================
epoch: 33, [batch: 1 / 1204], examples_per_second: 83.6895, train_label_loss: 2.3970, train_domain_loss: 0.5301
epoch: 33, [batch: 241 / 1204], examples_per_second: 12341.4262, train_label_loss: 2.3992, train_domain_loss: 0.5301
epoch: 33, [batch: 482 / 1204], examples_per_second: 12338.2363, train_label_loss: 2.3984, train_domain_loss: 0.5301
epoch: 33, [batch: 722 / 1204], examples_per_second: 12306.2638, train_label_loss: 2.3987, train_domain_loss: 0.5301
epoch: 33, [batch: 963 / 1204], examples_per_second: 12361.3557, train_label_loss: 2.3960, train_domain_loss: 0.5301
=============================================================
epoch: 33, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3979, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 1.0380
=============================================================
epoch: 34, [batch: 1 / 1204], examples_per_second: 83.5590, train_label_loss: 2.3964, train_domain_loss: 0.5301
epoch: 34, [batch: 241 / 1204], examples_per_second: 12213.8197, train_label_loss: 2.3934, train_domain_loss: 0.5300
epoch: 34, [batch: 482 / 1204], examples_per_second: 12393.6169, train_label_loss: 2.3995, train_domain_loss: 0.5301
epoch: 34, [batch: 722 / 1204], examples_per_second: 12330.2774, train_label_loss: 2.3980, train_domain_loss: 0.5301
epoch: 34, [batch: 963 / 1204], examples_per_second: 12236.8289, train_label_loss: 2.3999, train_domain_loss: 0.5301
=============================================================
epoch: 34, source_val_acc_label: 0.0903, target_val_acc_label: 0.0905, source_val_label_loss: 2.3980, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 1.0335
=============================================================
epoch: 35, [batch: 1 / 1204], examples_per_second: 82.5952, train_label_loss: 2.4024, train_domain_loss: 0.5301
epoch: 35, [batch: 241 / 1204], examples_per_second: 12247.7448, train_label_loss: 2.4005, train_domain_loss: 0.5318
epoch: 35, [batch: 482 / 1204], examples_per_second: 12340.3945, train_label_loss: 2.3934, train_domain_loss: 0.5300
epoch: 35, [batch: 722 / 1204], examples_per_second: 12401.2673, train_label_loss: 2.3968, train_domain_loss: 0.5306
epoch: 35, [batch: 963 / 1204], examples_per_second: 12308.0699, train_label_loss: 2.3977, train_domain_loss: 0.5301
=============================================================
epoch: 35, source_val_acc_label: 0.0905, target_val_acc_label: 0.0910, source_val_label_loss: 2.3980, target_val_label_loss: 2.3980, source_and_target_val_domain_loss: 1.0187
=============================================================
epoch: 36, [batch: 1 / 1204], examples_per_second: 83.8867, train_label_loss: 2.4003, train_domain_loss: 0.5301
epoch: 36, [batch: 241 / 1204], examples_per_second: 12229.7157, train_label_loss: 2.3986, train_domain_loss: 0.5301
epoch: 36, [batch: 482 / 1204], examples_per_second: 12308.0395, train_label_loss: 2.3962, train_domain_loss: 0.5301
epoch: 36, [batch: 722 / 1204], examples_per_second: 12331.4445, train_label_loss: 2.3993, train_domain_loss: 0.5301
epoch: 36, [batch: 963 / 1204], examples_per_second: 12335.1933, train_label_loss: 2.4023, train_domain_loss: 0.5301
=============================================================
epoch: 36, source_val_acc_label: 0.0903, target_val_acc_label: 0.0900, source_val_label_loss: 2.3980, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 1.0308
=============================================================
epoch: 37, [batch: 1 / 1204], examples_per_second: 83.3854, train_label_loss: 2.3965, train_domain_loss: 0.5301
epoch: 37, [batch: 241 / 1204], examples_per_second: 12329.9258, train_label_loss: 2.3968, train_domain_loss: 0.5301
epoch: 37, [batch: 482 / 1204], examples_per_second: 12336.7846, train_label_loss: 2.4009, train_domain_loss: 0.5301
epoch: 37, [batch: 722 / 1204], examples_per_second: 12321.8017, train_label_loss: 2.4015, train_domain_loss: 0.5301
epoch: 37, [batch: 963 / 1204], examples_per_second: 12074.6524, train_label_loss: 2.3990, train_domain_loss: 0.5266
=============================================================
epoch: 37, source_val_acc_label: 0.0871, target_val_acc_label: 0.0915, source_val_label_loss: 2.3980, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 1.0319
=============================================================
epoch: 38, [batch: 1 / 1204], examples_per_second: 83.7573, train_label_loss: 2.3961, train_domain_loss: 0.5301
epoch: 38, [batch: 241 / 1204], examples_per_second: 12167.8631, train_label_loss: 2.3957, train_domain_loss: 0.5301
epoch: 38, [batch: 482 / 1204], examples_per_second: 12233.8993, train_label_loss: 2.3933, train_domain_loss: 0.5301
epoch: 38, [batch: 722 / 1204], examples_per_second: 11910.6346, train_label_loss: 2.4000, train_domain_loss: 0.5301
epoch: 38, [batch: 963 / 1204], examples_per_second: 12340.9878, train_label_loss: 2.3970, train_domain_loss: 0.5301
=============================================================
epoch: 38, source_val_acc_label: 0.0930, target_val_acc_label: 0.0923, source_val_label_loss: 2.3980, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 0.9802
=============================================================
epoch: 39, [batch: 1 / 1204], examples_per_second: 82.1754, train_label_loss: 2.3926, train_domain_loss: 0.5301
epoch: 39, [batch: 241 / 1204], examples_per_second: 12292.1756, train_label_loss: 2.4035, train_domain_loss: 0.5301
epoch: 39, [batch: 482 / 1204], examples_per_second: 12310.2118, train_label_loss: 2.3970, train_domain_loss: 0.5301
epoch: 39, [batch: 722 / 1204], examples_per_second: 12302.6953, train_label_loss: 2.3975, train_domain_loss: 0.5301
epoch: 39, [batch: 963 / 1204], examples_per_second: 12285.8305, train_label_loss: 2.3945, train_domain_loss: 0.5301
=============================================================
epoch: 39, source_val_acc_label: 0.0871, target_val_acc_label: 0.0915, source_val_label_loss: 2.3980, target_val_label_loss: 2.3979, source_and_target_val_domain_loss: 1.0110
=============================================================
Patience (10) exhausted
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
Source Val Label Accuracy: 0.0903030303030303 Target Val Label Accuracy: 0.09053613053613054
Source Test Label Accuracy: 0.08831168831168831 Target Test Label Accuracy: 0.09263403263403264
[CONDUCTOR]: Done flushing
