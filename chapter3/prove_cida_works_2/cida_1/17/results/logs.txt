[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 2061.8469, train_label_loss: 2.7727, train_domain_loss: 0.5001
epoch: 1, [batch: 88 / 438], examples_per_second: 11279.9447, train_label_loss: 2.7091, train_domain_loss: 0.4650
epoch: 1, [batch: 175 / 438], examples_per_second: 11297.0234, train_label_loss: 2.6020, train_domain_loss: 0.4563
epoch: 1, [batch: 263 / 438], examples_per_second: 11975.5970, train_label_loss: 2.4653, train_domain_loss: 0.4360
epoch: 1, [batch: 350 / 438], examples_per_second: 11601.5583, train_label_loss: 1.7552, train_domain_loss: 0.4678
=============================================================
epoch: 1, source_val_acc_label: 0.5831, target_val_acc_label: 0.5772, source_val_label_loss: 1.3304, target_val_label_loss: 1.3347, source_and_target_val_domain_loss: 0.9138
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 186.6703, train_label_loss: 1.5675, train_domain_loss: 0.4381
epoch: 2, [batch: 88 / 438], examples_per_second: 11371.8747, train_label_loss: 1.0642, train_domain_loss: 0.5080
epoch: 2, [batch: 175 / 438], examples_per_second: 11461.8605, train_label_loss: 1.0881, train_domain_loss: 0.4516
epoch: 2, [batch: 263 / 438], examples_per_second: 11562.4489, train_label_loss: 1.0299, train_domain_loss: 0.4566
epoch: 2, [batch: 350 / 438], examples_per_second: 11521.9889, train_label_loss: 0.9799, train_domain_loss: 0.4966
=============================================================
epoch: 2, source_val_acc_label: 0.7343, target_val_acc_label: 0.7527, source_val_label_loss: 0.8163, target_val_label_loss: 0.8030, source_and_target_val_domain_loss: 0.9653
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 208.2665, train_label_loss: 0.7369, train_domain_loss: 0.4643
epoch: 3, [batch: 88 / 438], examples_per_second: 11837.9563, train_label_loss: 0.8922, train_domain_loss: 0.4762
epoch: 3, [batch: 175 / 438], examples_per_second: 12002.0293, train_label_loss: 0.7200, train_domain_loss: 0.4227
epoch: 3, [batch: 263 / 438], examples_per_second: 11869.5315, train_label_loss: 0.8746, train_domain_loss: 0.4544
epoch: 3, [batch: 350 / 438], examples_per_second: 11665.2596, train_label_loss: 0.6557, train_domain_loss: 0.4722
=============================================================
epoch: 3, source_val_acc_label: 0.8221, target_val_acc_label: 0.8305, source_val_label_loss: 0.6399, target_val_label_loss: 0.6360, source_and_target_val_domain_loss: 0.9685
=============================================================
New best
epoch: 4, [batch: 1 / 438], examples_per_second: 209.1999, train_label_loss: 0.6954, train_domain_loss: 0.4746
epoch: 4, [batch: 88 / 438], examples_per_second: 11641.9524, train_label_loss: 0.7131, train_domain_loss: 0.4787
epoch: 4, [batch: 175 / 438], examples_per_second: 11946.1519, train_label_loss: 0.4719, train_domain_loss: 0.4927
epoch: 4, [batch: 263 / 438], examples_per_second: 12186.0895, train_label_loss: 0.5320, train_domain_loss: 0.4356
epoch: 4, [batch: 350 / 438], examples_per_second: 11877.4062, train_label_loss: 0.4384, train_domain_loss: 0.4999
=============================================================
epoch: 4, source_val_acc_label: 0.7664, target_val_acc_label: 0.7899, source_val_label_loss: 0.6068, target_val_label_loss: 0.5913, source_and_target_val_domain_loss: 0.9808
=============================================================
New best
epoch: 5, [batch: 1 / 438], examples_per_second: 213.0640, train_label_loss: 0.4928, train_domain_loss: 0.5087
epoch: 5, [batch: 88 / 438], examples_per_second: 11520.9373, train_label_loss: 0.5686, train_domain_loss: 0.4175
epoch: 5, [batch: 175 / 438], examples_per_second: 11831.5781, train_label_loss: 0.2914, train_domain_loss: 0.5047
epoch: 5, [batch: 263 / 438], examples_per_second: 12139.6187, train_label_loss: 0.2680, train_domain_loss: 0.4339
epoch: 5, [batch: 350 / 438], examples_per_second: 12098.1265, train_label_loss: 0.4098, train_domain_loss: 0.4691
=============================================================
epoch: 5, source_val_acc_label: 0.8545, target_val_acc_label: 0.8831, source_val_label_loss: 0.5081, target_val_label_loss: 0.4966, source_and_target_val_domain_loss: 0.9808
=============================================================
New best
epoch: 6, [batch: 1 / 438], examples_per_second: 215.1610, train_label_loss: 0.2898, train_domain_loss: 0.4823
epoch: 6, [batch: 88 / 438], examples_per_second: 11620.2414, train_label_loss: 0.3466, train_domain_loss: 0.4708
epoch: 6, [batch: 175 / 438], examples_per_second: 12043.4268, train_label_loss: 0.4234, train_domain_loss: 0.4629
epoch: 6, [batch: 263 / 438], examples_per_second: 12020.9038, train_label_loss: 0.3743, train_domain_loss: 0.4837
epoch: 6, [batch: 350 / 438], examples_per_second: 12016.7861, train_label_loss: 0.4621, train_domain_loss: 0.4914
=============================================================
epoch: 6, source_val_acc_label: 0.5676, target_val_acc_label: 0.5537, source_val_label_loss: 0.8412, target_val_label_loss: 0.8559, source_and_target_val_domain_loss: 0.9660
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 220.6048, train_label_loss: 0.1791, train_domain_loss: 0.4475
epoch: 7, [batch: 88 / 438], examples_per_second: 11670.8706, train_label_loss: 0.6155, train_domain_loss: 0.4404
epoch: 7, [batch: 175 / 438], examples_per_second: 12144.5437, train_label_loss: 0.1799, train_domain_loss: 0.4412
epoch: 7, [batch: 263 / 438], examples_per_second: 12043.1042, train_label_loss: 0.5021, train_domain_loss: 0.4974
epoch: 7, [batch: 350 / 438], examples_per_second: 12027.5484, train_label_loss: 0.0894, train_domain_loss: 0.4512
=============================================================
epoch: 7, source_val_acc_label: 0.6845, target_val_acc_label: 0.6938, source_val_label_loss: 0.6228, target_val_label_loss: 0.6042, source_and_target_val_domain_loss: 0.9755
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 215.7142, train_label_loss: 0.1866, train_domain_loss: 0.4741
epoch: 8, [batch: 88 / 438], examples_per_second: 11590.3336, train_label_loss: 0.3484, train_domain_loss: 0.4374
epoch: 8, [batch: 175 / 438], examples_per_second: 11523.6689, train_label_loss: 0.2187, train_domain_loss: 0.4526
epoch: 8, [batch: 263 / 438], examples_per_second: 11549.3987, train_label_loss: 0.2301, train_domain_loss: 0.5108
epoch: 8, [batch: 350 / 438], examples_per_second: 11765.6050, train_label_loss: 0.2767, train_domain_loss: 0.4665
=============================================================
epoch: 8, source_val_acc_label: 0.8443, target_val_acc_label: 0.8363, source_val_label_loss: 0.4494, target_val_label_loss: 0.4424, source_and_target_val_domain_loss: 0.9756
=============================================================
New best
epoch: 9, [batch: 1 / 438], examples_per_second: 206.1305, train_label_loss: 0.3287, train_domain_loss: 0.4480
epoch: 9, [batch: 88 / 438], examples_per_second: 11029.1272, train_label_loss: 0.1664, train_domain_loss: 0.4943
epoch: 9, [batch: 175 / 438], examples_per_second: 11595.7834, train_label_loss: 0.0845, train_domain_loss: 0.4255
epoch: 9, [batch: 263 / 438], examples_per_second: 11644.9976, train_label_loss: 0.1821, train_domain_loss: 0.4825
epoch: 9, [batch: 350 / 438], examples_per_second: 11537.6027, train_label_loss: 0.1622, train_domain_loss: 0.4877
=============================================================
epoch: 9, source_val_acc_label: 0.9302, target_val_acc_label: 0.9482, source_val_label_loss: 0.3799, target_val_label_loss: 0.3690, source_and_target_val_domain_loss: 0.9749
=============================================================
New best
epoch: 10, [batch: 1 / 438], examples_per_second: 211.1999, train_label_loss: 0.3940, train_domain_loss: 0.4760
epoch: 10, [batch: 88 / 438], examples_per_second: 11693.2222, train_label_loss: 0.0682, train_domain_loss: 0.4987
epoch: 10, [batch: 175 / 438], examples_per_second: 11974.6593, train_label_loss: 0.1308, train_domain_loss: 0.4343
epoch: 10, [batch: 263 / 438], examples_per_second: 12039.6209, train_label_loss: 0.1988, train_domain_loss: 0.4654
epoch: 10, [batch: 350 / 438], examples_per_second: 12049.5009, train_label_loss: 0.2907, train_domain_loss: 0.4977
=============================================================
epoch: 10, source_val_acc_label: 0.9679, target_val_acc_label: 0.9719, source_val_label_loss: 0.3366, target_val_label_loss: 0.3301, source_and_target_val_domain_loss: 0.9804
=============================================================
New best
epoch: 11, [batch: 1 / 438], examples_per_second: 216.9557, train_label_loss: 0.0328, train_domain_loss: 0.5079
epoch: 11, [batch: 88 / 438], examples_per_second: 11497.6593, train_label_loss: 0.2029, train_domain_loss: 0.4548
epoch: 11, [batch: 175 / 438], examples_per_second: 11910.3191, train_label_loss: 0.2446, train_domain_loss: 0.4753
epoch: 11, [batch: 263 / 438], examples_per_second: 11951.9813, train_label_loss: 0.0975, train_domain_loss: 0.4886
epoch: 11, [batch: 350 / 438], examples_per_second: 12042.7033, train_label_loss: 0.0829, train_domain_loss: 0.4648
=============================================================
epoch: 11, source_val_acc_label: 0.8686, target_val_acc_label: 0.8846, source_val_label_loss: 0.3819, target_val_label_loss: 0.3700, source_and_target_val_domain_loss: 0.9786
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 218.6060, train_label_loss: 0.0316, train_domain_loss: 0.4318
epoch: 12, [batch: 88 / 438], examples_per_second: 11652.4605, train_label_loss: 0.1098, train_domain_loss: 0.4471
epoch: 12, [batch: 175 / 438], examples_per_second: 11763.3085, train_label_loss: 0.0806, train_domain_loss: 0.4632
epoch: 12, [batch: 263 / 438], examples_per_second: 12068.1051, train_label_loss: 0.0435, train_domain_loss: 0.5194
epoch: 12, [batch: 350 / 438], examples_per_second: 11882.5218, train_label_loss: -0.0955, train_domain_loss: 0.5022
=============================================================
epoch: 12, source_val_acc_label: 1.0000, target_val_acc_label: 1.0000, source_val_label_loss: 0.2536, target_val_label_loss: 0.2454, source_and_target_val_domain_loss: 0.9760
=============================================================
New best
epoch: 13, [batch: 1 / 438], examples_per_second: 215.3558, train_label_loss: 0.1781, train_domain_loss: 0.4814
epoch: 13, [batch: 88 / 438], examples_per_second: 11745.3531, train_label_loss: 0.0581, train_domain_loss: 0.4896
epoch: 13, [batch: 175 / 438], examples_per_second: 11667.3314, train_label_loss: 0.0658, train_domain_loss: 0.5050
epoch: 13, [batch: 263 / 438], examples_per_second: 11830.0023, train_label_loss: -0.1408, train_domain_loss: 0.5324
epoch: 13, [batch: 350 / 438], examples_per_second: 12034.7970, train_label_loss: 0.0554, train_domain_loss: 0.4748
=============================================================
epoch: 13, source_val_acc_label: 1.0000, target_val_acc_label: 1.0000, source_val_label_loss: 0.2278, target_val_label_loss: 0.2203, source_and_target_val_domain_loss: 0.9716
=============================================================
New best
epoch: 14, [batch: 1 / 438], examples_per_second: 210.8458, train_label_loss: -0.0735, train_domain_loss: 0.4877
epoch: 14, [batch: 88 / 438], examples_per_second: 11575.4947, train_label_loss: 0.3024, train_domain_loss: 0.5189
epoch: 14, [batch: 175 / 438], examples_per_second: 11861.7484, train_label_loss: -0.0395, train_domain_loss: 0.4462
epoch: 14, [batch: 263 / 438], examples_per_second: 12137.4948, train_label_loss: 0.0498, train_domain_loss: 0.4626
epoch: 14, [batch: 350 / 438], examples_per_second: 11933.1196, train_label_loss: 0.0543, train_domain_loss: 0.4628
=============================================================
epoch: 14, source_val_acc_label: 0.9026, target_val_acc_label: 0.9040, source_val_label_loss: 0.2747, target_val_label_loss: 0.2676, source_and_target_val_domain_loss: 0.9945
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 216.3634, train_label_loss: -0.0368, train_domain_loss: 0.4616
epoch: 15, [batch: 88 / 438], examples_per_second: 11747.8021, train_label_loss: 0.1187, train_domain_loss: 0.4392
epoch: 15, [batch: 175 / 438], examples_per_second: 11714.1141, train_label_loss: 0.1898, train_domain_loss: 0.4997
epoch: 15, [batch: 263 / 438], examples_per_second: 12066.3976, train_label_loss: 0.0172, train_domain_loss: 0.5094
epoch: 15, [batch: 350 / 438], examples_per_second: 12061.1659, train_label_loss: 0.3741, train_domain_loss: 0.5093
=============================================================
epoch: 15, source_val_acc_label: 0.9783, target_val_acc_label: 0.9859, source_val_label_loss: 0.2038, target_val_label_loss: 0.1993, source_and_target_val_domain_loss: 0.9803
=============================================================
New best
epoch: 16, [batch: 1 / 438], examples_per_second: 212.8631, train_label_loss: -0.0197, train_domain_loss: 0.4742
epoch: 16, [batch: 88 / 438], examples_per_second: 11592.2263, train_label_loss: -0.0963, train_domain_loss: 0.4765
epoch: 16, [batch: 175 / 438], examples_per_second: 11426.7424, train_label_loss: 0.0999, train_domain_loss: 0.4971
epoch: 16, [batch: 263 / 438], examples_per_second: 11640.4213, train_label_loss: -0.1030, train_domain_loss: 0.4694
epoch: 16, [batch: 350 / 438], examples_per_second: 11417.9964, train_label_loss: -0.0793, train_domain_loss: 0.4422
=============================================================
epoch: 16, source_val_acc_label: 1.0000, target_val_acc_label: 1.0000, source_val_label_loss: 0.1597, target_val_label_loss: 0.1576, source_and_target_val_domain_loss: 1.0020
=============================================================
New best
epoch: 17, [batch: 1 / 438], examples_per_second: 211.7674, train_label_loss: -0.0244, train_domain_loss: 0.4811
epoch: 17, [batch: 88 / 438], examples_per_second: 11701.4246, train_label_loss: -0.2187, train_domain_loss: 0.5460
epoch: 17, [batch: 175 / 438], examples_per_second: 11811.6094, train_label_loss: -0.2544, train_domain_loss: 0.5170
epoch: 17, [batch: 263 / 438], examples_per_second: 11676.2036, train_label_loss: -0.1723, train_domain_loss: 0.4679
epoch: 17, [batch: 350 / 438], examples_per_second: 12004.7099, train_label_loss: -0.1065, train_domain_loss: 0.5033
=============================================================
epoch: 17, source_val_acc_label: 0.5800, target_val_acc_label: 0.5753, source_val_label_loss: 0.7088, target_val_label_loss: 0.7072, source_and_target_val_domain_loss: 0.9916
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 223.0900, train_label_loss: 0.0365, train_domain_loss: 0.5030
epoch: 18, [batch: 88 / 438], examples_per_second: 11705.7737, train_label_loss: -0.1806, train_domain_loss: 0.4806
epoch: 18, [batch: 175 / 438], examples_per_second: 11708.5202, train_label_loss: -0.3012, train_domain_loss: 0.4893
epoch: 18, [batch: 263 / 438], examples_per_second: 11974.5407, train_label_loss: 0.2490, train_domain_loss: 0.5109
epoch: 18, [batch: 350 / 438], examples_per_second: 11565.6089, train_label_loss: -0.2088, train_domain_loss: 0.5028
=============================================================
epoch: 18, source_val_acc_label: 0.9379, target_val_acc_label: 0.9385, source_val_label_loss: 0.2256, target_val_label_loss: 0.2244, source_and_target_val_domain_loss: 0.9994
=============================================================
epoch: 19, [batch: 1 / 438], examples_per_second: 212.0752, train_label_loss: -0.0199, train_domain_loss: 0.4851
epoch: 19, [batch: 88 / 438], examples_per_second: 11627.5138, train_label_loss: -0.1036, train_domain_loss: 0.4583
epoch: 19, [batch: 175 / 438], examples_per_second: 11421.4725, train_label_loss: -0.0518, train_domain_loss: 0.4979
epoch: 19, [batch: 263 / 438], examples_per_second: 11742.7789, train_label_loss: 0.1028, train_domain_loss: 0.5466
epoch: 19, [batch: 350 / 438], examples_per_second: 11881.2493, train_label_loss: -0.2575, train_domain_loss: 0.5325
=============================================================
epoch: 19, source_val_acc_label: 0.9210, target_val_acc_label: 0.9196, source_val_label_loss: 0.1947, target_val_label_loss: 0.1935, source_and_target_val_domain_loss: 1.0022
=============================================================
epoch: 20, [batch: 1 / 438], examples_per_second: 216.4677, train_label_loss: -0.2519, train_domain_loss: 0.4504
epoch: 20, [batch: 88 / 438], examples_per_second: 11927.8415, train_label_loss: -0.2074, train_domain_loss: 0.4759
epoch: 20, [batch: 175 / 438], examples_per_second: 11980.2770, train_label_loss: -0.0755, train_domain_loss: 0.5124
epoch: 20, [batch: 263 / 438], examples_per_second: 11726.9430, train_label_loss: -0.2848, train_domain_loss: 0.5324
epoch: 20, [batch: 350 / 438], examples_per_second: 11744.2988, train_label_loss: -0.2539, train_domain_loss: 0.5117
=============================================================
epoch: 20, source_val_acc_label: 0.9905, target_val_acc_label: 0.9949, source_val_label_loss: 0.1295, target_val_label_loss: 0.1260, source_and_target_val_domain_loss: 1.0136
=============================================================
New best
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
Source Val Label Accuracy: 0.9904761904761905 Target Val Label Accuracy: 0.9948717948717949
Source Test Label Accuracy: 0.9911904761904762 Target Test Label Accuracy: 0.9944871794871795
[CONDUCTOR]: Done flushing
